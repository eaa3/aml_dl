{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Deep Ensamble MDN Toy Example ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We use the same network architecture: 1-hidden layer neural network with ReLU nonlinearity (Nair and Hinton, 2010), containing 50 hidden units for smaller datasets and 100 hidden units for the larger protein and Year Prediction MSD datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"We trained for 40 epochs; we refer to (Herna ́ndez-Lobato and Adams, 2015) for further details about the datasets and the experimental protocol. We used 5 networks in our ensemble. Our results are shown in Table 1, along with the PBP and MC-dropout results reported in their respective papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"On some datasets, we observe that our method is slightly worse in terms of RMSE. We believe that this might be caused due to the het- eroscedastic regression training criterion, which optimises for NLL instead of MSE as discussed in the toy example in Figure 3.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ermanoarruda/virtualenvs/robotics/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from aml_dl.mdn.model.tf_ensemble_mdn_model import EnsembleMDN\n",
    "\n",
    "from aml_dl.gp.simple_gp import GaussianProcess, kernel\n",
    "\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = 'exp_ensemble'\n",
    "\n",
    "\n",
    "adam_params = {\n",
    "    'type': 'adam',\n",
    "    'params': {'learning_rate' : 0.001, 'beta1': 0.9, 'beta2': 0.999, 'epsilon': 1e-08, 'use_locking': False}\n",
    "}\n",
    "\n",
    "network_params = {\n",
    "    'n_ensembles': 5,\n",
    "    'dim_input': 1, \n",
    "    'dim_output': 1,\n",
    "    'n_hidden': [100],#[20,20,10],\n",
    "    'k_mixtures': 1,\n",
    "    'write_summary': False,\n",
    "    'load_saved_model': False,\n",
    "#     'model_dir': check_point_dir + '/inv/',\n",
    "#     'model_name':'ensemble_model_inv_10_kernels.ckpt',\n",
    "    'optimiser': adam_params,\n",
    "#     'summary_dir':summary_dir+'/inv/',\n",
    "    'device': '/cpu:0',\n",
    "    'adv_epsilon': 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(42)\n",
    "np.random.seed(seed=42)¶\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_mdn = EnsembleMDN(network_params,sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_level = 0.1#0.00000001;\n",
    "width = 1.0 # 0.5\n",
    "scale = 30 # 30\n",
    "\n",
    "\n",
    "gp = GaussianProcess(noise_level, width, scale, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ensamble_mdn._init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun_h(t, noise_gain=0.):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "    return np.cos(2*t - 1/2)/2 + np.cos(t) + 1 + noise\n",
    "\n",
    "def fun_poly(t, noise_gain=0.):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "    return -0.01*(t ** 3) + np.square(t)*0.01 + noise\n",
    "\n",
    "def fun_cubic_poly(t, noise_gain=0.):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "    return 0.01*(t ** 3) + 0.01*noise\n",
    "\n",
    "# *\n",
    "def fun_s(t, noise_gain=0.):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "    return (t-8) ** 3 - 5 * (t - 8)\n",
    "\n",
    "def fun_c(t, noise_gain=0.0):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "        \n",
    "    return t * np.cos(t) + noise\n",
    "\n",
    "def fun_g(t, noise_gain=0.):\n",
    "    if len(t.shape) > 1:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0],t.shape[1])\n",
    "    else:\n",
    "        noise = noise_gain*np.random.randn(t.shape[0])\n",
    "    noise = noise_gain*np.random.randn(d1, d2)\n",
    "    return np.divide(np.power(np.multiply((np.sin(t) - np.sin(2*t)/2 + np.sin(3*t)/3. - \n",
    "                                           np.sin(4*t)/4. + 4),t),2),(t+1)) + noise\n",
    "\n",
    "def sawtoothxy(x,y):\n",
    "    t, r = cart2pol(x,y) # change to polar coordinates\n",
    "    h = fun_h(t)\n",
    "    g = fun_g(r)\n",
    "    f = np.multiply(g,h)\n",
    "    return f\n",
    "\n",
    "func_y = fun_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_points = 2000 # 1000\n",
    "x_values = np.linspace(-6, 6, num_data_points)\n",
    "y_values = fun_cubic_poly(x_values, 3.0)\n",
    "\n",
    "train_idx = np.random.choice(np.arange(300,1650),20)\n",
    "\n",
    "plt.plot(x_values, y_values, 'dodgerblue', linewidth=3.0)\n",
    "plt.plot(x_values[train_idx], y_values[train_idx], 'ro')\n",
    "# print x_values[300:1450]\n",
    "# print y_values[300:1450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_and_plot(i, loss):\n",
    "    \n",
    "    x_test = x_values#np.linspace(0, 12, num_data_points)\n",
    "    y_test = y_values #fun_h(x_test, 0.0)\n",
    "    \n",
    "    out_mus = ensamble_mdn.run_op(sess, 'mus', np.expand_dims(x_test,axis=1))\n",
    "    out_sigma = ensamble_mdn.run_op(sess, 'sigmas', np.expand_dims(x_test,axis=1))\n",
    "    out_pis = ensamble_mdn.run_op(sess, 'pis', np.expand_dims(x_test,axis=1))\n",
    "    \n",
    "    mean_out, var_out = ensamble_mdn.forward(sess, np.expand_dims(x_test,axis=1))\n",
    "    \n",
    "    stddev = 3.0\n",
    "    fig2 = plt.figure(1,figsize=(15,15))\n",
    "    fig2.clf()\n",
    "    ax = fig2.add_subplot(411)\n",
    "\n",
    "    ypl = [float(mu-stddev*np.sqrt(sig)) for mu,sig in zip(mean_out,var_out)]\n",
    "    yph = [float(mu+stddev*np.sqrt(sig)) for mu,sig in zip(mean_out,var_out)]\n",
    "\n",
    "    ax.plot(x_test, y_test, color='r')\n",
    "\n",
    "    ax.fill_between(x_test.tolist(), ypl, yph, facecolor='grey', interpolate=True, alpha=0.9)\n",
    "    ax.plot(x_test, mean_out, color='b', linewidth=2.5)\n",
    "\n",
    "#     colours = np.random.rand((network_params['n_ensembles'],3))#['g','c','k','m','y','']\n",
    "\n",
    "    for k in range(network_params['n_ensembles']):\n",
    "        ax.plot(x_test, np.reshape(out_mus[k],(-1,)), color=(np.random.rand(), np.random.rand(), np.random.rand()),linewidth=0.5)\n",
    "\n",
    "    ax.scatter(x_train, y_train)\n",
    "\n",
    "#     plt.show()\n",
    "    \n",
    "    plt.title('Iteration %d'%(i,))\n",
    "    \n",
    "    ax2 = fig2.add_subplot(412)\n",
    "    mloss = np.mean(loss,axis=0)\n",
    "    ax2.plot(mloss[:None], 'r-')\n",
    "    \n",
    "    ax3 = fig2.add_subplot(413)\n",
    "    ax3.plot(x_test, np.sqrt(var_out), color='g')\n",
    "    \n",
    "    \n",
    "    return fig2, mloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = x_values[350:650,None]\n",
    "# y_train = y_values[350:650,None]\n",
    "# x_train = x_values[600:900,None]\n",
    "# y_train = y_values[600:900,None]\n",
    "\n",
    "# x_train = x_values[753:1054,None]\n",
    "# y_train = y_values[753:1054,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = np.vstack([x_values[15:20,None],x_values[45:50,None],x_values[75:80,None]])\n",
    "# y_train = np.vstack([y_values[15:20,None],y_values[45:50,None],y_values[75:80,None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = np.vstack([x_values[200:400,None],x_values[750:1000,None],x_values[1250:1450,None]])\n",
    "# y_train = np.vstack([y_values[200:400,None],y_values[750:1000,None],y_values[1250:1450,None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.vstack([x_values[train_idx,None]])\n",
    "y_train = np.vstack([y_values[train_idx,None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for idx in range(x_train.shape[0]):\n",
    "    gp.update(x_train[idx,:], y_train[idx,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, cov, logp = gp.predict3(x_values)\n",
    "std = np.sqrt(np.diagonal(cov))*3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_posterior = gp.sample_multivariate(pred, cov, len(pred), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(2, figsize=(8,8))\n",
    "plt.errorbar(x_values, pred, yerr=std, fmt='r-', ecolor='g', elinewidth=0.25, linewidth=3.5)\n",
    "plt.plot(x_values, y_values, 'dodgerblue', linewidth=3.0)\n",
    "# plt.plot(x_values, sample_posterior)\n",
    "# plt.xlim([0,12])\n",
    "# plt.ylim([-0,3.0])\n",
    "plt.plot(gp.x, gp.y, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stddev = 1.9600 #3.0\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(211)\n",
    "ypl = [float(mu-stddev*np.sqrt(sig)) for mu,sig in zip(pred,std)]\n",
    "yph = [float(mu+stddev*np.sqrt(sig)) for mu,sig in zip(pred,std)]\n",
    "\n",
    "ax.plot(x_values, y_values, color='r')\n",
    "\n",
    "ax.fill_between(x_values.tolist(), ypl, yph, facecolor='grey', interpolate=True, alpha=0.9)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "ax2.plot(x_values, np.sqrt(std), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x_train,y_train)\n",
    "plt.plot(x_values,y_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterations = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_loss = []\n",
    "for i in range(40):\n",
    "    loss = ensamble_mdn.train(x_train, y_train, sess, iterations)\n",
    "\n",
    "#     fig, mloss = test_and_plot(i, loss)\n",
    "#     mean_loss.append(np.mean(mloss))\n",
    "#     ax2 = fig.add_subplot(414)\n",
    "#     ax2.plot(mean_loss, 'r-')\n",
    "    \n",
    "#     display.display(plt.gcf())\n",
    "#     display.clear_output(wait=True)\n",
    "#     time.sleep(0.001)\n",
    "    \n",
    "#     ax = fig2.add_subplot(212)\n",
    "#     ax.plot(np.arange(100, iterations,1), loss[0, 100:], 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_values#np.linspace(0, 12, num_data_points)\n",
    "y_test = y_values #fun_h(x_test, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_mus = ensamble_mdn.run_op(sess, 'mus', np.expand_dims(x_test,axis=1))\n",
    "out_sigma = ensamble_mdn.run_op(sess, 'sigmas', np.expand_dims(x_test,axis=1))\n",
    "out_pis = ensamble_mdn.run_op(sess, 'pis', np.expand_dims(x_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out_mus = np.reshape(out_mus,(-1,1))\n",
    "# out_sigma = np.reshape(out_sigma,(-1,1))\n",
    "# out_pis = np.reshape(out_pis,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print np.reshape(out_mus[0],(-1,1))\n",
    "# print out_sigma.shape\n",
    "# print out_pis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_out, var_out = ensamble_mdn.forward(sess, np.expand_dims(x_test,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stddev = 3.0#1.9600 #3.0\n",
    "\n",
    "fig2 = plt.figure(2, figsize=(8,8))\n",
    "# plt.xlim([0,12])\n",
    "plt.ylim([-3.0,3.0])\n",
    "plt.xlim([-6.0,6.0])\n",
    "ax = fig2.add_subplot(111)\n",
    "\n",
    "ypl = [float(mu-stddev*np.sqrt(sig[0])) for mu,sig in zip(mean_out,var_out)]\n",
    "yph = [float(mu+stddev*np.sqrt(sig[0])) for mu,sig in zip(mean_out,var_out)]\n",
    "\n",
    "plt.plot(x_values, y_values, 'dodgerblue', linewidth=3.0)\n",
    "\n",
    "\n",
    "ax.fill_between(x_test.tolist(), ypl, yph, facecolor='grey', interpolate=True, alpha=0.9)\n",
    "\n",
    "ax.plot(x_test.flatten(), mean_out.flatten(), color='b', linewidth=2.5)\n",
    "\n",
    "colours = ['g','c','k','m','y']\n",
    "\n",
    "for k in range(network_params['n_ensembles']):\n",
    "    y_em = np.reshape(out_mus[k],(-1,))\n",
    "    ax.plot(x_test, y_em, color=(np.random.rand(),np.random.rand(),np.random.rand()),linewidth=0.5)\n",
    "\n",
    "# plt.scatter(x_train,y_train)\n",
    "plt.plot(x_train, y_train, 'ro')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
